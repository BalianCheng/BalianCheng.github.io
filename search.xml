<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Adaboost]]></title>
      <url>http://www.codingbalian.online/2016/12/20/Adaboost/</url>
      <content type="html"><![CDATA[<p>#Adaboost<br>Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。<br><a id="more"></a><br>Adaboost过程：</p>
<ol>
<li>先通过对N个训练样本的学习得到第一个弱分类器；</li>
<li>将分错的样本和其他的新数据一起构成一个新的N个的训练样本，通过对这个样本的学习得到第二个弱分类器 ；</li>
<li>将1和2都分错了的样本加上其他的新样本构成另一个新的N个的训练样本，通过对这个样本的学习得到第三个弱分类器；</li>
<li>最终经过提升的强分类器。即某个数据被分为哪一类要由各分类器权值决定。</li>
</ol>
<p>训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量D。一开始，这些权重都初始化成相等值。首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本的权重将会提高。为了从所有弱分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个弱分类器的错误率进行计算的。<br>错误率ε的定义为<br>$$ε=\frac{未正确分类的样本数}{所有样本数}$$<br>alpha：<br>$$α=\frac{1}{2}ln\frac{1-ε}{ε}$$<br><img src="http://i1.piimg.com/567571/f46e6188192028b6.png" alt=""><br>AdaBoost算法的示意图。左边是数据集，其中直方图的不同宽度表示每个样例上的不同权重。在经过一个分类器之后，加权的预测结果会通过三角形中的alpha值进行加权。每个三角形中输出的加权结果在圆形中求和，从而得到最终的输出结果计算出alpha值之后，可以对权重向量D进行更新，以使得那些正确分类的样本的权重降低而错分样本的权重升高。<br>D的计算方法如下:<br>如果某个样本被正确分类，那么该样本的权重更改为：<br>$$D_i^{(t+1)}=\frac{D_i^{(t)}e^-α}{Sum(D)}$$<br>而如果某个样本被错分，那么该样本的权重更改为：<br>$$D_i^{(t+1)}=\frac{D_i^{(t)}e^α}{Sum(D)}$$<br>在计算出D之后，AdaBoost又开始进入下一轮迭代。Ad-aBoost算法会不断地重复训练和调整权重的过程，直到训练错误率为0或者弱分类器的数目达到用户的指定值为止。</p>
<p>##自适应数据加载函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">def loadDataSet(filename):  </div><div class="line">    numFeat = len(open(filename).readline().split(&apos;\t&apos;))  </div><div class="line">    dataMat = []  </div><div class="line">    labelMat=[]  </div><div class="line">    fr = open(filename)  </div><div class="line">    for line in fr.readlines():  </div><div class="line">        lineArr= []  </div><div class="line">        curLine = line.strip(&apos;\n&apos;).split(&apos;\t&apos;)  </div><div class="line">        for i in range(numFeat - 1):  </div><div class="line">            lineArr.append(float(curLine[i]))  </div><div class="line">        dataMat.append(lineArr)  </div><div class="line">        labelMat.append(float(curLine[-1]))  </div><div class="line">    fr.close()  </div><div class="line">    return dataMat, labelMat</div></pre></td></tr></table></figure></p>
<blockquote>
<p>并不指定每个文件中的特特征树木，可以自动检测，并假定最后一个特征是类别标签</p>
</blockquote>
<p>##单层决策树生成函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):  </div><div class="line">    retArray = ones((shape(dataMatrix)[0],1))  </div><div class="line">    if threshIneq == &apos;lt&apos;:  </div><div class="line">        retArray[dataMatrix[:,dimen]&lt;threshVal] = -1.0  </div><div class="line">    else:  </div><div class="line">        retArray[dataMatrix[:,dimen]&lt;threshVal] = -1.0  </div><div class="line">    return retArray  </div><div class="line"></div><div class="line">def buildStump(dataArr, classLabels, D):  </div><div class="line">    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T  </div><div class="line">    m,n = shape(dataMatrix)  </div><div class="line">    numSteps = 10.0; bestStump = &#123;&#125;; #定义一个空字典，用于存储给定权重向量D时所得到的最佳单层决策树的相关信息  </div><div class="line">	bestClassEst = mat(zeros((m,1)))  </div><div class="line">    minError = inf  #最小错误率初始化为无穷大</div><div class="line">    for i in range(n):  #在所有数据集的所有特征上遍历  </div><div class="line">        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();  </div><div class="line">        stepSize = (rangeMax - rangeMin)/numSteps #通过计算特征的最小值和最大值来计算步长，numSteps越大，步长越小   </div><div class="line">        for j in range(-1, int(numSteps)+1):  #按分的步长总数进行循环</div><div class="line">            for inequal in [&apos;lt&apos;,&apos;gt&apos;]:  </div><div class="line">                threshVal = (rangeMin + float(j)*stepSize)  </div><div class="line">                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)  </div><div class="line">                errArr = mat(ones((m,1)))   #构建错误数组  errArr，如果predict-edVals中的值不等于labelMat中的真正类别标签值，那么errArr的相应位置为1</div><div class="line">                errArr[predictedVals == labelMat] = 0  </div><div class="line">                weightedError = D.T * errArr           #这里的error是错误向量errArr和权重向量D的相应元素相乘得到的即加权错误率  </div><div class="line">                #print &quot;split: dim %d, thresh %.2f, thresh inequal: %s, the weighted error is %.3f&quot; %(i, threshVal, inequal, weightedError)  </div><div class="line">                if weightedError &lt; minError:  </div><div class="line">                    minError = weightedError  </div><div class="line">                    bestClassEst = predictedVals.copy()  </div><div class="line">                    bestStump[&apos;dim&apos;] = i  </div><div class="line">                    bestStump[&apos;thresh&apos;] = threshVal  </div><div class="line">                    bestStump[&apos;ineq&apos;] = inequal  </div><div class="line">    return bestStump, minError, bestClassEst #返回分类的最小错误率</div></pre></td></tr></table></figure>
<blockquote>
<p>stumpClassify()通过阈值比较进行分类，可以通过数组过滤实现，首先将返回的元素全部设置为1，不满足等式的元素设置为为-1。<br>buildStump()有三层循环构建了单层决策树，最外层循环为遍历特征，次外层循环为遍历的步长，最内层为是否大于或小于阀值。构建的最小错误率为加权错误率，这就是为什么增加分错样本的权重，因为分错样本的权重增加了，下次如果继续分错，加权错误率会很大，这就不满足算法最小化加权错误率了。此外，加权错误率在每次迭代过程中一定是逐次降低的。<br>单层决策树的生成函数是决策树的一个简化版本。它就是所谓的弱学习器，即弱分类算法。</p>
</blockquote>
<h2 id="基于单层决策树的adaboost训练过程"><a href="#基于单层决策树的adaboost训练过程" class="headerlink" title="基于单层决策树的adaboost训练过程"></a>基于单层决策树的adaboost训练过程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">def adaBoostTrainDS(dataArr, classLabels, numIt = 40):  </div><div class="line">    weakClassArr = []  #建立一个单层决策树数组</div><div class="line">    m = shape(dataArr)[0]  #得到数据点的数目</div><div class="line">    D = mat(ones((m,1))/m) #向量D非常重要，它包含了每个数据点的权重 </div><div class="line">    aggClassEst = mat(zeros((m,1)))#列向量aggClassEst，记录每个数据点的类别估计累计值  </div><div class="line">    for i in range(numIt):  </div><div class="line">        bestStump, error, classEst = buildStump(dataArr, classLabels, D)  #bestStump=字典,error=分类错误率,classEst=列向量，预测之后的分类列表</div><div class="line">       # print &quot;D:&quot;, D.T  </div><div class="line">        alpha = float(0.5 * log((1.0 - error)/max(error, 1e-16)))   #确保在没有错误时不会发生除零溢出  </div><div class="line">        bestStump[&apos;alpha&apos;] = alpha  </div><div class="line">        weakClassArr.append(bestStump)  </div><div class="line">        #print &quot;classEst:&quot;, classEst.T  </div><div class="line">        expon = multiply(-1 * alpha * mat(classLabels).T, classEst)    #乘法用于区分是否正确或者错误样本,样本被正确分类的话expon为负，错误分类的话为正,其中第一次分对的样本的权重将会降低，而第一次分错的样本的权重将会提高  </div><div class="line">        D = multiply(D, exp(expon))  #计算新权重向量D  </div><div class="line">        D = D/D.sum()            # 归一化用的  </div><div class="line">        aggClassEst += alpha * classEst    #累加变成强分类器  </div><div class="line">        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m,1)))  </div><div class="line">        errorRate = aggErrors.sum()/m  </div><div class="line">        print &quot;total error: &quot;, errorRate, &quot;\n&quot;  </div><div class="line">        if errorRate == 0.0: break  </div><div class="line">    return weakClassArr, aggClassEst</div></pre></td></tr></table></figure>
<blockquote>
<p>对每次迭代：<br>  利用buildStump()函数找到最佳的单层决策树<br>  将最佳单层决策树加入到单层决策树数组<br>  计算alpha<br>  计算新的权重向量D<br>  更新累计类别估计值<br>  如果错误率等于0.0，则退出循环<br>我们假定迭代次数设为9，如果算法在第三次迭代之后错误率为0，那么就会退出迭代过程，因此，此时就不需要执行所有的9次迭代过程。每次迭代的中间结果都会通过print语句进行输出。</p>
</blockquote>
<p>##adaboost分类函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">def adaClassify(datToClass, classifierArr):  </div><div class="line">    dataMatrix = mat(datToClass)  </div><div class="line">    m = shape(dataMatrix)[0]  </div><div class="line">    aggClassEst = mat(zeros((m,1)))  </div><div class="line">    for i in range(len(classifierArr)):  </div><div class="line">        classEst = stumpClassify(dataMatrix, classifierArr[i][&apos;dim&apos;], classifierArr[i][&apos;thresh&apos;], classifierArr[i][&apos;ineq&apos;])  </div><div class="line">        aggClassEst += classifierArr[i][&apos;alpha&apos;]*classEst  </div><div class="line">        print aggClassEst  </div><div class="line">    return sign(aggClassEst)</div></pre></td></tr></table></figure></p>
<blockquote>
<p>adaClassify()函数就是利用训练出的多个弱分类器进行分类的函数。该函数的输入是由一个或者多个待分类样例datToClass以及多个弱分类器组成的数组classifierArr。程序返回aggClassEst的符号，即如果aggClassEst大于0则返回+1，而如果小于0则返回-1。</p>
</blockquote>
<p>##画决策树的图<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">def plot_Fig(xMat,yMat,weakClassArr):  </div><div class="line">    xMat = mat(xMat)  </div><div class="line">    fig = plt.figure()  </div><div class="line">    ax = fig.add_subplot(111)  </div><div class="line">    for i in range(len(yMat)):  </div><div class="line">        if yMat[i] == -1.0: #如果标签为-1，则将数据点标为蓝色方块  </div><div class="line">            ax.scatter(xMat[i,0],xMat[i,1],color=&apos;b&apos;,marker=&apos;s&apos;) #注意flatten的用法  </div><div class="line">        else:  #如果标签为1，则将数据点标为红色圆形  </div><div class="line">            ax.scatter(xMat[i,0],xMat[i,1],color=&apos;r&apos;,marker=&apos;o&apos;)  </div><div class="line">    for i in range(len(weakClassArr)): #根据弱分类器数组画出决策树图形  </div><div class="line">        if weakClassArr[i].get(&quot;dim&quot;) == 0:   </div><div class="line">            y = arange(0.0,3.0,0.1)  </div><div class="line">            x = weakClassArr[i].get(&quot;thresh&quot;) #得到阈值  </div><div class="line">            x = repeat(x,len(y))  </div><div class="line">            ax.plot(x,y)  </div><div class="line">        if weakClassArr[i].get(&quot;dim&quot;) == 1:  </div><div class="line">            x = arange(0.0,3.0,0.1)  </div><div class="line">            y = weakClassArr[i].get(&quot;thresh&quot;)  </div><div class="line">            y = repeat(y,len(x))  </div><div class="line">            ax.plot(x,y)   </div><div class="line">    plt.show()</div></pre></td></tr></table></figure></p>
<p>##ROC曲线<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">&lt;span style=&quot;font-size:12px;&quot;&gt;def plotROC(predStrengths, classLabels):  </div><div class="line">    import matplotlib.pyplot as plt  </div><div class="line">    cur = (1.0,1.0) #cursor绘制光标的位置  </div><div class="line">    ySum = 0.0 #variable to calculate AUC；用于计算AUC的值  </div><div class="line">    numPosClas = sum(array(classLabels)==1.0) #计算正例的数目  </div><div class="line">    yStep = 1/float(numPosClas); #确定y坐标轴上的步长，因为当y为1时，对应的正例个数为numPosClas  </div><div class="line">    xStep = 1/float(len(classLabels)-numPosClas) #计算x坐标轴上的步长，因为当x为1时，对应的负例个数为总数减去numPosClas  </div><div class="line">    sortedIndicies = predStrengths.argsort()#get sorted index, it&apos;s reverse  </div><div class="line">    fig = plt.figure()  </div><div class="line">    fig.clf()  </div><div class="line">    ax = plt.subplot(111)  </div><div class="line">    #loop through all the values, drawing a line segment at each point  </div><div class="line">    for index in sortedIndicies.tolist()[0]: #利用tolist()转化为列表，  </div><div class="line">        if classLabels[index] == 1.0: #每得到一个标签为1.0的类，沿着y轴的方向下降一个步长，即不断降低真阳率（好好体会为什么这样做）  </div><div class="line">            delX = 0; delY = yStep;  </div><div class="line">        else:  </div><div class="line">            delX = xStep; delY = 0; #类似   </div><div class="line">            ySum += cur[1] #先对所有矩形的高度进行累加（当y值下降时不累加），最后再乘以xStep就是其总面积。  </div><div class="line">        #draw line from cur to (cur[0]-delX,cur[1]-delY)  </div><div class="line">        ax.plot([cur[0],cur[0]-delX],[cur[1],cur[1]-delY], c=&apos;b&apos;)  </div><div class="line">        cur = (cur[0]-delX,cur[1]-delY) #更新绘制光标的位置  </div><div class="line">    ax.plot([0,1],[0,1],&apos;b--&apos;)  </div><div class="line">    plt.xlabel(&apos;False positive rate&apos;); plt.ylabel(&apos;True positive rate&apos;)  </div><div class="line">    plt.title(&apos;ROC curve for AdaBoost horse colic detection system&apos;)  </div><div class="line">    ax.axis([0,1,0,1])  </div><div class="line">    print &quot;the Area Under the Curve is: &quot;,ySum*xStep  </div><div class="line">    plt.show()&lt;/span&gt;</div></pre></td></tr></table></figure></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[github pages + Hexo + 域名绑定]]></title>
      <url>http://www.codingbalian.online/2016/12/19/github-pages-Hexo/</url>
      <content type="html"><![CDATA[<p>本文从安装环境开始详细讲述如何使用github pages + Hexo搭建自己的静态博客，并且使用阿里云绑定域名。<br><a id="more"></a><br><strong>环境</strong></p>
<ol>
<li>安装Git<img src="http://oifuxc6w5.bkt.clouddn.com/git.png" alt=""></li>
<li>安装Node<img src="http://oifuxc6w5.bkt.clouddn.com/NODEJS.png" alt=""></li>
<li>验证安装<img src="http://oifuxc6w5.bkt.clouddn.com/cmd.png" alt=""></li>
</ol>
<p><strong>Github Pages</strong><br> 在GitHub创建一个格式为：yourusername.github.io的仓库即可。<br><img src="http://oifuxc6w5.bkt.clouddn.com/gitmaven.png" alt=""><br><strong>Hexo</strong><br>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>建立一个blog文件夹用于存放博客文件,然后右键单击选择“Git Bash”。<br><code>npm install hexo-cli -g</code><br><code>hexo init blog</code><br><code>cd blog</code><br><code>npm install</code><br><code>hexo server</code><br>执行hexo server时，默认端口是4000,如果端口被占用更换即可。<br>如<code>hexo server -p 4001</code><br>访问<code>http://localhost:4000/</code><br><img src="http://oifuxc6w5.bkt.clouddn.com/hexo.png" alt=""><br><strong>更换主题</strong><br>exo-theme：<a href="https://hexo.io/themes/" target="_blank" rel="external">https://hexo.io/themes/</a><br>hexo-github-theme-list：<a href="https://github.com/hexojs/hexo/wiki/Themes" target="_blank" rel="external">https://github.com/hexojs/hexo/wiki/Themes</a><br><code>git clone</code>加上主题地址<br>_config.yml中将theme改成刚刚下载的主题<br>修改完成后<code>hexo generate</code>  <code>hexo server</code>重启服务器查看效果<br><img src="http://oifuxc6w5.bkt.clouddn.com/newtheme.png" alt=""><br><strong>部署代码到github</strong><br><code>ssh-keygen -t rsa -C &quot;你的邮箱地址&quot;</code>生成SSH秘钥<br>在<a href="https://github.com/settings/ssh" target="_blank" rel="external">https://github.com/settings/ssh</a> 添加id_rsa.pub中的秘钥<br>安装插件：<br><code>npm install hexo -server --save</code><br><code>npm install hexo-deployer-git --save</code><br>安装其他插件的格式为<code>npm install ... --save</code><br>编辑全局 hexo 的配置文件：<code>_config.yml</code><br>注意<code>:</code>后留一个空格<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">type: git</div><div class="line">repository: https://github.com/BalianCheng/BalianCheng.github.io.git</div><div class="line">branch: master</div></pre></td></tr></table></figure></p>
<p>编辑全局配置后需要重新部署：<br>清除掉已经生成的文件：<code>hexo clean</code><br>再生成静态文件：<code>hexo generate</code><br>预览：<code>hexo server</code><br>打开<code>localhost:4000</code>查看<br>部署：<code>hexo deploy</code><br>生成 40 4页面：<code>hexo new page 404</code><br>生成 about 页面：<code>hexo new page about</code><br>生成 tag 标签云页面：<code>hexo new page tags</code><br><strong>绑定域名</strong><br><code>ping yourname.github.io</code>获得IP地址并使用域名解析<br>进入GitHub项目,进入<code>Settings</code>,在<code>Custom domain</code>写入域名<br>在\blog\public下建立CNAME文件写入域名</p>
]]></content>
    </entry>
    
  
  
</search>
